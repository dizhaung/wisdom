{
    "docs": [
        {
            "location": "/",
            "text": "Wisdom Stream Processor\n\n\nWisdom is an adaptive, distributed and self-boosting stream processor written in Java 9 using modern architecture from the scratch. Though I designed and developed Wisdom for my research project, my OCD in designing scalable and extensible architecture made Wisdom an industry ready product with all basic requirements. I admit that Wisdom may lack some features that you are looking for. For example, right now Wisdom does not support database integration. It is only because my research did not require those features and I do not have enough time to add those extra nice-to-have features. After publishing all my research works, Wisdom will be made open source.\n\n\nAbout Author\n\n\nGobinath is a research assistant at the University of Western Ontario, Canada. He completed his bachelor's degree at the University of Moratuwa, Sri Lanka with a first class and joined \nWSO2\n a middleware company providing open source solutions for agile digital business. He spent 9 months in WSO2 Research and Development Analytics team where he had on hand experience on stream processing. Though he used stream processor for his undergraduate research project, at WSO2 he designed and developed Complex Event Processing (CEP) operators for \nSiddhi\n CEP engine.\n\n\nSiddhi is an open source CEP engine with tons of features and being used by over 60 companies including \nUBER\n. Following features were designed and developed by Gobinath:\n\n\nEvent Window\n\n\nA global window that can be reused to avoid duplicating windows in more than one places.\n\n\ndefine stream SensorStream (name string, value float, roomNo int, deviceID string);\ndefine stream KitchenSensorStream (name string, value float, deviceID string);\ndefine window SensorWindow (name string, value float, roomNo int, deviceID string) timeBatch(1 second);\n\n@info(name = 'query0')\nfrom SensorStream\ninsert into SensorWindow;\n\n@info(name = 'query1')\nfrom  KitchenSensorStream\nselect name, value, 10 as  roomNo, deviceID\ninsert into SensorWindow;\n\n\n\n\nAbsent Event Pattern\n\n\nLogical pattern to detect events those have not arrived.\n\n\ndefine stream CustomerStream (customerId string);\n\n@info(name = 'query1')\nfrom not CustomerStream for 1 sec\nselect *\ninsert into OutputStream;\n\n\n\n\nSiddhi Debugger\n\n\nA complete debugger to track events in Siddhi and to debug them along with a terminal endpoint.\n\n\nSiddhiManager siddhiManager = new SiddhiManager();\n\nString cseEventStream = \"@config(async = 'true') define stream cseEventStream (symbol string, price float, \" +\n        \"volume int);\";\nfinal String query = \"@info(name = 'query 1')\" +\n        \"from cseEventStream \" +\n        \"select symbol, price, volume \" +\n        \"insert into OutputStream; \";\n\nExecutionPlanRuntime executionPlanRuntime = siddhiManager.createExecutionPlanRuntime(cseEventStream + query);\nInputHandler inputHandler = executionPlanRuntime.getInputHandler(\"cseEventStream\");\n\nSiddhiDebugger siddhiDebugger = executionPlanRuntime.debug();\nsiddhiDebugger.acquireBreakPoint(\"query 1\", SiddhiDebugger.QueryTerminal.IN);\n\nsiddhiDebugger.setDebuggerCallback(new SiddhiDebuggerCallback() {\n    @Override\n    public void debugEvent(ComplexEvent event, String queryName, SiddhiDebugger.QueryTerminal queryTerminal,\n                            SiddhiDebugger debugger) {\n        log.info(\"Query: \" + queryName + \":\" + queryTerminal);\n        log.info(event);\n        debugger.next();\n    }\n});\n\ninputHandler.send(new Object[]{\"WSO2\", 50f, 60});\ninputHandler.send(new Object[]{\"WSO2\", 70f, 40});\nexecutionPlanRuntime.shutdown();\n\n\n\n\nSiddhi Event Playback\n\n\n@Plan:playback\ndefine stream cseEventStream (symbol string, price float, volume int);\n\n@info(name = 'query1')\nfrom cseEventStream#window.timeBatch(1 sec)\nselect *\ninsert all events into outputStream ;\n\n\n\n\nSiddhi Reverse Geocode Extension\n\n\ndefine stream LocationStream (deviceId string, timestamp long, latitude double, longitude double);\n@info(name = 'query1')\nfrom LocationStream#geo:reversegeocode(latitude, longitude)\nselect streetNumber, neighborhood, route, administrativeAreaLevelTwo, administrativeAreaLevelOne, country, countryCode, postalCode, formattedAddress\ninsert into OutputStream\n\n\n\n\nProximity Marketting Usecase\n\n\nThe proximity marketting use cased developed by Gobinath using WSO2 Stream Processor is being used to demonstrate the product to clients.\n\n\n@Plan:name('RealtimeAnalytics-ExecutionPlan-ProductOfferGenerator')\n\n@Plan:description('Based on the proximity of the user, send offers to the user')\n\n\n@Import('org.wso2.realtime.analytics.stream.CustomerLocation:1.0.0')\ndefine stream CustomerLocationStream (meta_timestamp long, customerId string, floorNumber int, shelfNumber int);\n\n@Export('org.wso2.realtime.analytics.stream.SendOffer:1.0.0')\ndefine stream SendOfferStream (meta_userId string, meta_timestamp long, productName string, offerName string, offerDescription string, expirationDate long);\n\n@IndexBy('id')\n@From(eventtable='rdbms', datasource.name='WSO2_REALTIME_ANALYTICS_BEACON', table.name='ORG_WSO2_REALTIME_ANALYTICS_EVENT_TABLE_ITEM')\ndefine table ItemEventTable (id string, name string, category string, floorNumber int, shelfNumber int, offerId string);\n\n@IndexBy('id')\n@From(eventtable='rdbms', datasource.name='WSO2_REALTIME_ANALYTICS_BEACON', table.name='ORG_WSO2_REALTIME_ANALYTICS_EVENT_TABLE_OFFER')\ndefine table OfferEventTable (id string, name string, description string, expirationDate long);\n\n/* Find if the user is in the same location continuously more than 5 seconds */\nfrom every(loc1 = CustomerLocationStream) -> loc2 = CustomerLocationStream[(meta_timestamp > loc1.meta_timestamp) AND (floorNumber == loc1.floorNumber) AND (shelfNumber == loc1.shelfNumber)]<0:> -> loc3 = CustomerLocationStream[(meta_timestamp >= loc1.meta_timestamp + 30000) AND (floorNumber == loc1.floorNumber) AND (shelfNumber == loc1.shelfNumber)]\nwithin 5 sec\nselect loc1.customerId as userId, loc3.meta_timestamp as timestamp, loc1.floorNumber as floorNumber, loc1.shelfNumber as shelfNumber\ninsert into #ProximityStream;\n\n/* Find if the event is triggered for the same series of events. The same pattern identified within a day is ignored to avoid spaming. For testing purpose 5 minutes is used */\nfrom #ProximityStream as leftStream left outer join #ProximityStream#window.time(5 minutes) as rightStream on leftStream.userId == rightStream.userId AND leftStream.floorNumber == rightStream.floorNumber AND leftStream.shelfNumber == rightStream.shelfNumber\nselect leftStream.userId as userId, leftStream.timestamp as timestamp, leftStream.floorNumber as floorNumber, leftStream.shelfNumber as shelfNumber, rightStream.userId IS NULL as isNewEvent\ninsert into #ProximityPerDayStream;\n\n/* Allow only new event patterns to trigger offer */\nfrom #ProximityPerDayStream[isNewEvent]\nselect userId, timestamp, floorNumber, shelfNumber\ninsert into #FilteredProximityStream;\n\n/* Find whether the product has an offer */\nfrom #FilteredProximityStream as proximity join ItemEventTable as item on proximity.floorNumber == item.floorNumber AND proximity.shelfNumber == item.shelfNumber AND item.offerId != \"N/A\"\nselect proximity.userId as userId, proximity.timestamp as timestamp, item.id as itemId, item.name as productName, item.offerId as offerId\ninsert into #ItemStream;\n\n/* Validate offer expiary peiod and send the offer */\nfrom #ItemStream as item join OfferEventTable as offer on item.offerId == offer.id AND item.timestamp <= offer.expirationDate\nselect item.userId as meta_userId, item.timestamp as meta_timestamp, item.productName as productName, offer.name as offerName, offer.description as offerDescription, offer.expirationDate as expirationDate\ninsert into SendOfferStream;\n\n\n\n\nIn addition, he also fixed several concurrency issues and HA deployment issues. Later, he moved to Canada for his higher studies and developed his own stream processor: \nWisdom\n for his research requirement. Wisdom can optimize itself for better results and self-boost for resource utilization.\n\n\nIf you like to invest in Wisdom, please contact me via \nslgobinath@gmail.com\n. If you are looking for an easy to use stream processor with fresh design and less complexity for your research, you are at the right place. Just drop me an email: \nslgobinath@gmail.com\n.",
            "title": "Home"
        },
        {
            "location": "/#wisdom-stream-processor",
            "text": "Wisdom is an adaptive, distributed and self-boosting stream processor written in Java 9 using modern architecture from the scratch. Though I designed and developed Wisdom for my research project, my OCD in designing scalable and extensible architecture made Wisdom an industry ready product with all basic requirements. I admit that Wisdom may lack some features that you are looking for. For example, right now Wisdom does not support database integration. It is only because my research did not require those features and I do not have enough time to add those extra nice-to-have features. After publishing all my research works, Wisdom will be made open source.",
            "title": "Wisdom Stream Processor"
        },
        {
            "location": "/#about-author",
            "text": "Gobinath is a research assistant at the University of Western Ontario, Canada. He completed his bachelor's degree at the University of Moratuwa, Sri Lanka with a first class and joined  WSO2  a middleware company providing open source solutions for agile digital business. He spent 9 months in WSO2 Research and Development Analytics team where he had on hand experience on stream processing. Though he used stream processor for his undergraduate research project, at WSO2 he designed and developed Complex Event Processing (CEP) operators for  Siddhi  CEP engine.  Siddhi is an open source CEP engine with tons of features and being used by over 60 companies including  UBER . Following features were designed and developed by Gobinath:  Event Window  A global window that can be reused to avoid duplicating windows in more than one places.  define stream SensorStream (name string, value float, roomNo int, deviceID string);\ndefine stream KitchenSensorStream (name string, value float, deviceID string);\ndefine window SensorWindow (name string, value float, roomNo int, deviceID string) timeBatch(1 second);\n\n@info(name = 'query0')\nfrom SensorStream\ninsert into SensorWindow;\n\n@info(name = 'query1')\nfrom  KitchenSensorStream\nselect name, value, 10 as  roomNo, deviceID\ninsert into SensorWindow;  Absent Event Pattern  Logical pattern to detect events those have not arrived.  define stream CustomerStream (customerId string);\n\n@info(name = 'query1')\nfrom not CustomerStream for 1 sec\nselect *\ninsert into OutputStream;  Siddhi Debugger  A complete debugger to track events in Siddhi and to debug them along with a terminal endpoint.  SiddhiManager siddhiManager = new SiddhiManager();\n\nString cseEventStream = \"@config(async = 'true') define stream cseEventStream (symbol string, price float, \" +\n        \"volume int);\";\nfinal String query = \"@info(name = 'query 1')\" +\n        \"from cseEventStream \" +\n        \"select symbol, price, volume \" +\n        \"insert into OutputStream; \";\n\nExecutionPlanRuntime executionPlanRuntime = siddhiManager.createExecutionPlanRuntime(cseEventStream + query);\nInputHandler inputHandler = executionPlanRuntime.getInputHandler(\"cseEventStream\");\n\nSiddhiDebugger siddhiDebugger = executionPlanRuntime.debug();\nsiddhiDebugger.acquireBreakPoint(\"query 1\", SiddhiDebugger.QueryTerminal.IN);\n\nsiddhiDebugger.setDebuggerCallback(new SiddhiDebuggerCallback() {\n    @Override\n    public void debugEvent(ComplexEvent event, String queryName, SiddhiDebugger.QueryTerminal queryTerminal,\n                            SiddhiDebugger debugger) {\n        log.info(\"Query: \" + queryName + \":\" + queryTerminal);\n        log.info(event);\n        debugger.next();\n    }\n});\n\ninputHandler.send(new Object[]{\"WSO2\", 50f, 60});\ninputHandler.send(new Object[]{\"WSO2\", 70f, 40});\nexecutionPlanRuntime.shutdown();  Siddhi Event Playback  @Plan:playback\ndefine stream cseEventStream (symbol string, price float, volume int);\n\n@info(name = 'query1')\nfrom cseEventStream#window.timeBatch(1 sec)\nselect *\ninsert all events into outputStream ;  Siddhi Reverse Geocode Extension  define stream LocationStream (deviceId string, timestamp long, latitude double, longitude double);\n@info(name = 'query1')\nfrom LocationStream#geo:reversegeocode(latitude, longitude)\nselect streetNumber, neighborhood, route, administrativeAreaLevelTwo, administrativeAreaLevelOne, country, countryCode, postalCode, formattedAddress\ninsert into OutputStream  Proximity Marketting Usecase  The proximity marketting use cased developed by Gobinath using WSO2 Stream Processor is being used to demonstrate the product to clients.  @Plan:name('RealtimeAnalytics-ExecutionPlan-ProductOfferGenerator')\n\n@Plan:description('Based on the proximity of the user, send offers to the user')\n\n\n@Import('org.wso2.realtime.analytics.stream.CustomerLocation:1.0.0')\ndefine stream CustomerLocationStream (meta_timestamp long, customerId string, floorNumber int, shelfNumber int);\n\n@Export('org.wso2.realtime.analytics.stream.SendOffer:1.0.0')\ndefine stream SendOfferStream (meta_userId string, meta_timestamp long, productName string, offerName string, offerDescription string, expirationDate long);\n\n@IndexBy('id')\n@From(eventtable='rdbms', datasource.name='WSO2_REALTIME_ANALYTICS_BEACON', table.name='ORG_WSO2_REALTIME_ANALYTICS_EVENT_TABLE_ITEM')\ndefine table ItemEventTable (id string, name string, category string, floorNumber int, shelfNumber int, offerId string);\n\n@IndexBy('id')\n@From(eventtable='rdbms', datasource.name='WSO2_REALTIME_ANALYTICS_BEACON', table.name='ORG_WSO2_REALTIME_ANALYTICS_EVENT_TABLE_OFFER')\ndefine table OfferEventTable (id string, name string, description string, expirationDate long);\n\n/* Find if the user is in the same location continuously more than 5 seconds */\nfrom every(loc1 = CustomerLocationStream) -> loc2 = CustomerLocationStream[(meta_timestamp > loc1.meta_timestamp) AND (floorNumber == loc1.floorNumber) AND (shelfNumber == loc1.shelfNumber)]<0:> -> loc3 = CustomerLocationStream[(meta_timestamp >= loc1.meta_timestamp + 30000) AND (floorNumber == loc1.floorNumber) AND (shelfNumber == loc1.shelfNumber)]\nwithin 5 sec\nselect loc1.customerId as userId, loc3.meta_timestamp as timestamp, loc1.floorNumber as floorNumber, loc1.shelfNumber as shelfNumber\ninsert into #ProximityStream;\n\n/* Find if the event is triggered for the same series of events. The same pattern identified within a day is ignored to avoid spaming. For testing purpose 5 minutes is used */\nfrom #ProximityStream as leftStream left outer join #ProximityStream#window.time(5 minutes) as rightStream on leftStream.userId == rightStream.userId AND leftStream.floorNumber == rightStream.floorNumber AND leftStream.shelfNumber == rightStream.shelfNumber\nselect leftStream.userId as userId, leftStream.timestamp as timestamp, leftStream.floorNumber as floorNumber, leftStream.shelfNumber as shelfNumber, rightStream.userId IS NULL as isNewEvent\ninsert into #ProximityPerDayStream;\n\n/* Allow only new event patterns to trigger offer */\nfrom #ProximityPerDayStream[isNewEvent]\nselect userId, timestamp, floorNumber, shelfNumber\ninsert into #FilteredProximityStream;\n\n/* Find whether the product has an offer */\nfrom #FilteredProximityStream as proximity join ItemEventTable as item on proximity.floorNumber == item.floorNumber AND proximity.shelfNumber == item.shelfNumber AND item.offerId != \"N/A\"\nselect proximity.userId as userId, proximity.timestamp as timestamp, item.id as itemId, item.name as productName, item.offerId as offerId\ninsert into #ItemStream;\n\n/* Validate offer expiary peiod and send the offer */\nfrom #ItemStream as item join OfferEventTable as offer on item.offerId == offer.id AND item.timestamp <= offer.expirationDate\nselect item.userId as meta_userId, item.timestamp as meta_timestamp, item.productName as productName, offer.name as offerName, offer.description as offerDescription, offer.expirationDate as expirationDate\ninsert into SendOfferStream;  In addition, he also fixed several concurrency issues and HA deployment issues. Later, he moved to Canada for his higher studies and developed his own stream processor:  Wisdom  for his research requirement. Wisdom can optimize itself for better results and self-boost for resource utilization.  If you like to invest in Wisdom, please contact me via  slgobinath@gmail.com . If you are looking for an easy to use stream processor with fresh design and less complexity for your research, you are at the right place. Just drop me an email:  slgobinath@gmail.com .",
            "title": "About Author"
        },
        {
            "location": "/why-wisdom/",
            "text": "There are plenty of stream processors out there but Wisdom does not just increase the count. It is adaptive, distributable and self-boosting without compromising the performance.\n\n\nAdaptive and Tunable\n\n\nOne of the key selling point of Wisdom is its adaptiveness. Wisdom queries can be defined using variables and Wisdom will tune them based on a loss function you define. For example, we defined three \nWisdom rules\n to detect intrusions but in none of them we defined the time window interval or the minimum count threshold. Instead, Wisdom mined and optimized those values from training data. Obtained optimal values gave us \n99% accuracy\n in intrusion detection. Isn't that cool?\n\n\nOptimization algorithms and other techniques are submitted to a conference. I will share the link here once it is published.\n\n\nPerformace\n\n\nA common limitation I have observed in dynamic stream processors \nis their performance bottleneck. I designed the underlying architecure of Wisdom in such a way that it is comparable with existing commercial stream processors. I developed a simple filter query to compare Wisdom with \nApache Flink\n, \nWSO2 Siddhi\n and \nEsper CEP\n. The throughput and latency of \nWisdom is closed to WSO2 Siddhi and better than Esper\n. Exact perfomance results are included in the research paper.\n\n\nSelf-Boosting\n\n\nIn our research, we have shown that Wisdom consumes significantly fewer system resources than other distributed stream processors. The complete deployment setup and how it works are described in our research paper. However, I can leak that the proposed distributed deployment consumed \n1.5 times less memory\n than monolithic deployment.\n\n\nWisdom Query\n\n\nWisdom Query is an SQL like query inspired by \nSiddhi Query\n. An expressive query language hides the complexity of stream processing and make it super easy to use stream processors. In addition, it lets you deploy CEP applications via REST API calls instead of transfering a deployable \njar\n file or any other binary file.",
            "title": "Why Wisdom?"
        },
        {
            "location": "/why-wisdom/#adaptive-and-tunable",
            "text": "One of the key selling point of Wisdom is its adaptiveness. Wisdom queries can be defined using variables and Wisdom will tune them based on a loss function you define. For example, we defined three  Wisdom rules  to detect intrusions but in none of them we defined the time window interval or the minimum count threshold. Instead, Wisdom mined and optimized those values from training data. Obtained optimal values gave us  99% accuracy  in intrusion detection. Isn't that cool?  Optimization algorithms and other techniques are submitted to a conference. I will share the link here once it is published.",
            "title": "Adaptive and Tunable"
        },
        {
            "location": "/why-wisdom/#performace",
            "text": "A common limitation I have observed in dynamic stream processors \nis their performance bottleneck. I designed the underlying architecure of Wisdom in such a way that it is comparable with existing commercial stream processors. I developed a simple filter query to compare Wisdom with  Apache Flink ,  WSO2 Siddhi  and  Esper CEP . The throughput and latency of  Wisdom is closed to WSO2 Siddhi and better than Esper . Exact perfomance results are included in the research paper.",
            "title": "Performace"
        },
        {
            "location": "/why-wisdom/#self-boosting",
            "text": "In our research, we have shown that Wisdom consumes significantly fewer system resources than other distributed stream processors. The complete deployment setup and how it works are described in our research paper. However, I can leak that the proposed distributed deployment consumed  1.5 times less memory  than monolithic deployment.",
            "title": "Self-Boosting"
        },
        {
            "location": "/why-wisdom/#wisdom-query",
            "text": "Wisdom Query is an SQL like query inspired by  Siddhi Query . An expressive query language hides the complexity of stream processing and make it super easy to use stream processors. In addition, it lets you deploy CEP applications via REST API calls instead of transfering a deployable  jar  file or any other binary file.",
            "title": "Wisdom Query"
        },
        {
            "location": "/getting-started/",
            "text": "Wisdom offers a complete Java API and Wisdom query to develop Complex Event Processing (CEP) applications. Wisdom can be used as a Java library or standalone service. Java library is recommended for testing purposes, small scale applications and Android applications. If you are developing a resource consuming CEP application, it is recommended to use Wisdom Service. Wisdom Service is the only way to use HTTP Source and Sinks. This section explains how to create a simple CEP application using Wisdom Java API and Wisdom Query.\n\n\nRequirements\n\n\nMake sure that you have set up the following softwares in your system before building Wisdom.\n\n\n\n\nJava 9 (or latest)\n\n\nApache Maven\n\n\nApache Kafka (for self-boosting deployment)\n\n\n\n\nInstallation\n\n\nPlease contact me (\nslgobinath@gmail.com\n) to get access to Wisdom source code. Once you have downloaded the Wisdom source code, follow these steps to build and install Wisdom library.\n\n\nOpen your terminal and change directory\n\n\ncd wisdom\n\n\n\n\nCompile and install Wisdom using Apache Maven\n\n\nmvn clean install\n\n\n\n\nWisdom Java API\n\n\nCreate a new Maven Project in your favorite IDE. We use \nIntelliJ IDEA\n throughout this document.\n\n\nOpen the \npom.xml\n file add \nwisdom-core\n and optionally \nlogback\n dependencies as shown below:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n        <slf4j.version>1.7.25</slf4j.version>\n        <logback.version>1.2.3</logback.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>\n\n\n\n\nCreate a new Java class \ncom.javahelps.helloworld.javaapi.HelloWorld\n with the following code.\n\n\npackage com.javahelps.helloworld.javaapi;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.operator.Operator;\nimport com.javahelps.wisdom.core.stream.InputHandler;\nimport com.javahelps.wisdom.core.util.EventGenerator;\nimport com.javahelps.wisdom.core.util.EventPrinter;\n\npublic class HelloWorld {\n\n    public static void main(String[] args) {\n\n        // Create a Wisdom application\n        WisdomApp app = new WisdomApp(\"WisdomApp\", \"1.0.0\");\n\n        // Define streams\n        app.defineStream(\"StockStream\");\n        app.defineStream(\"OutputStream\");\n\n        // Create a query\n        app.defineQuery(\"FilterQuery\")\n                .from(\"StockStream\")\n                .filter(Operator.EQUALS(\"symbol\", \"AMAZON\"))\n                .select(\"symbol\", \"price\")\n                .insertInto(\"OutputStream\");\n\n        // Add output stream callback\n        app.addCallback(\"OutputStream\", EventPrinter::print);\n\n        // Get an input handler\n        InputHandler inputHandler = app.getInputHandler(\"StockStream\");\n\n        // Start the application\n        app.start();\n\n        // Send three inputs\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"GOOGLE\", \"price\", 10.5, \"volume\", 10L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"AMAZON\", \"price\", 20.5, \"volume\", 20L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"FACEBOOK\", \"price\", 30.5, \"volume\", 30L));\n\n        // Shutdown the application\n        app.shutdown();\n    }\n}\n\n\n\n\nAbove code creates Wisdom application with two streams: \nStockStream\n and \nOutputStream\n, and a query named \nFilterQuery\n. The \nFilterQuery\n filters stock events of \nAMAZON\n, select \nsymbol\n and \nprice\n, and insert them into the \nOutputStream\n. \nInputHandler\n is used to feed events to a stream and callback is used to receive events from a stream.\n\n\nRunning this code should print an output similar to this:\n\n\n[Event{timestamp=1524709449322, stream=OutputStream, data={symbol=AMAZON, price=20.5}, expired=false}]\n\n\n\n\nAs you can see, above Wisdom app filters events having symbol equal to AMAZON and prints them to the console.\n\n\nWisdom Query\n\n\nAbove Wisdom application can be defined using the folloing Wisdom query:\n\n\n@app(name='WisdomApp', version='1.0.0')\ndef stream StockStream;\ndef stream OutputStream;\n\n@query(name='FilterQuery')\nfrom StockStream\nfilter symbol == 'AMAZON'\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nTo use this query in a Java application, create a new Maven project in your favorite IDE.\n\n\nOpen the \npom.xml\n file and add \nwisdom-core\n, \nwisdom-query\n and optionally \nlogback\n dependencies as shown below:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n        <slf4j.version>1.7.25</slf4j.version>\n        <logback.version>1.2.3</logback.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-query</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>\n\n\n\n\nCreate a new Java class \ncom.javahelps.helloworld.wisdomql.HelloWorld\n with the following code.\n\n\npackage com.javahelps.helloworld.wisdomql;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.stream.InputHandler;\nimport com.javahelps.wisdom.core.util.EventGenerator;\nimport com.javahelps.wisdom.core.util.EventPrinter;\nimport com.javahelps.wisdom.query.WisdomCompiler;\n\npublic class HelloWorld {\n\n    public static void main(String[] args) {\n\n        String query = \"@app(name='WisdomApp', version='1.0.0') \" +\n                \"def stream StockStream; \" +\n                \"def stream OutputStream; \" +\n                \" \" +\n                \"@query(name='FilterQuery') \" +\n                \"from StockStream \" +\n                \"filter symbol == 'AMAZON' \" +\n                \"select symbol, price \" +\n                \"insert into OutputStream;\";\n\n        // Create a Wisdom application\n        WisdomApp app = WisdomCompiler.parse(query);\n\n        // Add output stream callback\n        app.addCallback(\"OutputStream\", EventPrinter::print);\n\n        // Get an input handler\n        InputHandler inputHandler = app.getInputHandler(\"StockStream\");\n\n        // Start the application\n        app.start();\n\n        // Send three inputs\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"GOOGLE\", \"price\", 10.5, \"volume\", 10L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"AMAZON\", \"price\", 20.5, \"volume\", 20L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"FACEBOOK\", \"price\", 30.5, \"volume\", 30L));\n\n        // Shutdown the application\n        app.shutdown();\n    }\n}\n\n\n\n\nAbove code replaces the Java API used in previous example by the Wisdom query to construct a Wisdom app. Once the Wisdom app is created, creating InputHandler and sending events are same as the previous example.",
            "title": "Getting Started"
        },
        {
            "location": "/getting-started/#requirements",
            "text": "Make sure that you have set up the following softwares in your system before building Wisdom.   Java 9 (or latest)  Apache Maven  Apache Kafka (for self-boosting deployment)",
            "title": "Requirements"
        },
        {
            "location": "/getting-started/#installation",
            "text": "Please contact me ( slgobinath@gmail.com ) to get access to Wisdom source code. Once you have downloaded the Wisdom source code, follow these steps to build and install Wisdom library.  Open your terminal and change directory  cd wisdom  Compile and install Wisdom using Apache Maven  mvn clean install",
            "title": "Installation"
        },
        {
            "location": "/getting-started/#wisdom-java-api",
            "text": "Create a new Maven Project in your favorite IDE. We use  IntelliJ IDEA  throughout this document.  Open the  pom.xml  file add  wisdom-core  and optionally  logback  dependencies as shown below:  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n        <slf4j.version>1.7.25</slf4j.version>\n        <logback.version>1.2.3</logback.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>  Create a new Java class  com.javahelps.helloworld.javaapi.HelloWorld  with the following code.  package com.javahelps.helloworld.javaapi;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.operator.Operator;\nimport com.javahelps.wisdom.core.stream.InputHandler;\nimport com.javahelps.wisdom.core.util.EventGenerator;\nimport com.javahelps.wisdom.core.util.EventPrinter;\n\npublic class HelloWorld {\n\n    public static void main(String[] args) {\n\n        // Create a Wisdom application\n        WisdomApp app = new WisdomApp(\"WisdomApp\", \"1.0.0\");\n\n        // Define streams\n        app.defineStream(\"StockStream\");\n        app.defineStream(\"OutputStream\");\n\n        // Create a query\n        app.defineQuery(\"FilterQuery\")\n                .from(\"StockStream\")\n                .filter(Operator.EQUALS(\"symbol\", \"AMAZON\"))\n                .select(\"symbol\", \"price\")\n                .insertInto(\"OutputStream\");\n\n        // Add output stream callback\n        app.addCallback(\"OutputStream\", EventPrinter::print);\n\n        // Get an input handler\n        InputHandler inputHandler = app.getInputHandler(\"StockStream\");\n\n        // Start the application\n        app.start();\n\n        // Send three inputs\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"GOOGLE\", \"price\", 10.5, \"volume\", 10L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"AMAZON\", \"price\", 20.5, \"volume\", 20L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"FACEBOOK\", \"price\", 30.5, \"volume\", 30L));\n\n        // Shutdown the application\n        app.shutdown();\n    }\n}  Above code creates Wisdom application with two streams:  StockStream  and  OutputStream , and a query named  FilterQuery . The  FilterQuery  filters stock events of  AMAZON , select  symbol  and  price , and insert them into the  OutputStream .  InputHandler  is used to feed events to a stream and callback is used to receive events from a stream.  Running this code should print an output similar to this:  [Event{timestamp=1524709449322, stream=OutputStream, data={symbol=AMAZON, price=20.5}, expired=false}]  As you can see, above Wisdom app filters events having symbol equal to AMAZON and prints them to the console.",
            "title": "Wisdom Java API"
        },
        {
            "location": "/getting-started/#wisdom-query",
            "text": "Above Wisdom application can be defined using the folloing Wisdom query:  @app(name='WisdomApp', version='1.0.0')\ndef stream StockStream;\ndef stream OutputStream;\n\n@query(name='FilterQuery')\nfrom StockStream\nfilter symbol == 'AMAZON'\nselect symbol, price\ninsert into OutputStream;  To use this query in a Java application, create a new Maven project in your favorite IDE.  Open the  pom.xml  file and add  wisdom-core ,  wisdom-query  and optionally  logback  dependencies as shown below:  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n        <slf4j.version>1.7.25</slf4j.version>\n        <logback.version>1.2.3</logback.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-query</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-core</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n\n        <dependency>\n            <groupId>ch.qos.logback</groupId>\n            <artifactId>logback-classic</artifactId>\n            <version>${logback.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>  Create a new Java class  com.javahelps.helloworld.wisdomql.HelloWorld  with the following code.  package com.javahelps.helloworld.wisdomql;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.stream.InputHandler;\nimport com.javahelps.wisdom.core.util.EventGenerator;\nimport com.javahelps.wisdom.core.util.EventPrinter;\nimport com.javahelps.wisdom.query.WisdomCompiler;\n\npublic class HelloWorld {\n\n    public static void main(String[] args) {\n\n        String query = \"@app(name='WisdomApp', version='1.0.0') \" +\n                \"def stream StockStream; \" +\n                \"def stream OutputStream; \" +\n                \" \" +\n                \"@query(name='FilterQuery') \" +\n                \"from StockStream \" +\n                \"filter symbol == 'AMAZON' \" +\n                \"select symbol, price \" +\n                \"insert into OutputStream;\";\n\n        // Create a Wisdom application\n        WisdomApp app = WisdomCompiler.parse(query);\n\n        // Add output stream callback\n        app.addCallback(\"OutputStream\", EventPrinter::print);\n\n        // Get an input handler\n        InputHandler inputHandler = app.getInputHandler(\"StockStream\");\n\n        // Start the application\n        app.start();\n\n        // Send three inputs\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"GOOGLE\", \"price\", 10.5, \"volume\", 10L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"AMAZON\", \"price\", 20.5, \"volume\", 20L));\n        inputHandler.send(EventGenerator.generate(\"symbol\", \"FACEBOOK\", \"price\", 30.5, \"volume\", 30L));\n\n        // Shutdown the application\n        app.shutdown();\n    }\n}  Above code replaces the Java API used in previous example by the Wisdom query to construct a Wisdom app. Once the Wisdom app is created, creating InputHandler and sending events are same as the previous example.",
            "title": "Wisdom Query"
        },
        {
            "location": "/deploy-wisdom/",
            "text": "Wisdom offers three different deployment options: (1) in-app usage as a Java library, (2) stand-alone deployment as a microservice, (3) Wisdom Orchestra deployment.\n\n\nWisdom Library\n\n\nThis is the recommended method to use Wisdom if you are developing a new Wisdom rule or if you want to playwith Wisdom. It is also recommended for applications require in-app complex event processing. Please check the \nGetting Started\n guidelines to use Wisdom as a library.\n\n\nWisdom Service\n\n\nWisdom Service is recommended if you are deploying a stand-alone CEP rule which requires HTTP endpoints and/or more system resources to be allocated. You can either use the Wisdom server to run your query or develop your own microservice to run your Wisdom app.\n\n\nDeploy Wisdom Query Using Wisdom Server\n\n\nStep 1:\n Email the author(\nslgobinath@gmail.com\n) and get the Wisdom Server pack.\n\n\nStep 2:\n Extract the zip file and navigate into the extracted directory.\n\n\nunzip product-wisdom-0.0.1.zip\ncd product-wisdom-0.0.1\n\n\n\n\nStep 3:\n Save the following Wisdom query into the \nartifacts\n directory with a name: \nstock_filter.wisdomql\n.\n\n\n@app(name='stock_filter', version='1.0.0')\n\n@source(type='http', mapping='json')\ndef stream StockStream;\n\n@sink(type='console')\ndef stream OutputStream;\n\n@query(name='FilterQuery')\nfrom StockStream\nfilter symbol == 'AMAZON'\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nStep 4:\n Start the Wisdom Service on port \n8080\n using the following command:\n\n\nsh wisdom-service.sh --port 8080 artifacts/stock_filter.wisdomql\n\n\n\n\nStep 5:\n Using \nPostman\n or similar tools, send an event using HTTP POST request. For simplicity, we use \ncurl\n to send the request.\n\n\ncurl -d '{\"symbol\": \"AMAZON\", \"price\": 120.0, \"volume\": 10}' -H \"Content-Type: application/json\" -X POST http://localhost:8080/WisdomApp/StockStream\n\n\n\n\nAfter sending this request, you should see the the following output in the terminal running Wisdom service:\n\n\nEvent{timestamp=1524757628355, stream=OutputStream, data={symbol=AMAZON, price=120.0}, expired=false}\n\n\n\n\nWisdom Orchestra\n\n\nWisdom Orchestra deployment is a fancy name I use to refer managing Wisdom instances using Wisdom Manager. Wisdom Manager is a specially designed tool to deploy and manage Wisdom services. It can be used to deploy stand-alone Wisdom services or to deploy self-boosting Wisdom environment.\n\n\nWisdom Manager often requires \nApache Kafka\n to coordinate and communicate with Wisdom instances. Therefore, please setup and start Apache Kakfa before running Wisdom Manager.\n\n\nStep 1:\n Download and extract the latest \nApache Kafka\n anywhere in your system.\n\n\nStep 2:\n Start Apache Kafka using the following two commands from \nKAFKA_HOME\n.\n\n\n# Start Zookeeper server\nsh bin/zookeeper-server-start.sh config/zookeeper.properties\n\n# Start Kafka server\nsh bin/kafka-server-start.sh config/server.properties\n\n\n\n\nStep 3:\n Open another terminal in \nWISDOM_HOME\n and start the Wisdom Manager.\n\n\nsh wisdom-manager.sh\n\n\n\n\nStep 4:\n Send an HTTP POST request with a Wisdom query along with a port to start that query.\n\n\ncurl -d \"{\\\"query\\\": \\\"@app(name='stock_filter', version='1.0.0') \\\n@source(type='http', mapping='json') \\\ndef stream StockStream; \\\n@sink(type='file.text', path='/tmp/OutputStream.txt') \\\ndef stream OutputStream; \\\n@query(name='FilterQuery') \\\nfrom StockStream \\\nfilter symbol == 'AMAZON' \\\nselect symbol, price \\\ninsert into OutputStream;\\\", \\\"port\\\": 8085}\" -H \"Content-Type: application/json\" -X POST http://localhost:8080/WisdomManager/app\n\n\n\n\nNote that the OutputStream sink is a text file: \n/tmp/OutputStream.txt\n.\n\n\nStep 5:\n Start \nstock_filter\n by sending another POST request.\n\n\ncurl -X POST http://localhost:8080/WisdomManager/start/stock_filter\n\n\n\n\nStep 06:\n Test \nstock_filter\n by sending a stock event.\n\n\ncurl -d '{\"symbol\": \"AMAZON\", \"price\": 120.0, \"volume\": 10}' -H \"Content-Type: application/json\" -X POST http://localhost:8085/WisdomApp/StockStream\n\n\n\n\nAfter sending above event, you should have a file \n/tmp/OutputStream.txt\n with the following content:\n\n\nEvent{timestamp=1524761284277, stream=OutputStream, data={symbol=AMAZON, price=120.0}, expired=false}\n\n\n\n\nStep 07:\n Stop the \nstock_filter\n app\n\n\ncurl -X POST http://localhost:8080/WisdomManager/stop/stock_filter\n\n\n\n\nStep 08:\n Delete the \nstock_filter\n app\n\n\ncurl -X DELETE http://localhost:8080/WisdomManager/app/stock_filter\n\n\n\n\nStep 09:\n Stop the Wisdom Manager\n\n\ncurl -X POST http://localhost:8080/WisdomManager/stop",
            "title": "Deploy Wisdom"
        },
        {
            "location": "/deploy-wisdom/#wisdom-library",
            "text": "This is the recommended method to use Wisdom if you are developing a new Wisdom rule or if you want to playwith Wisdom. It is also recommended for applications require in-app complex event processing. Please check the  Getting Started  guidelines to use Wisdom as a library.",
            "title": "Wisdom Library"
        },
        {
            "location": "/deploy-wisdom/#wisdom-service",
            "text": "Wisdom Service is recommended if you are deploying a stand-alone CEP rule which requires HTTP endpoints and/or more system resources to be allocated. You can either use the Wisdom server to run your query or develop your own microservice to run your Wisdom app.  Deploy Wisdom Query Using Wisdom Server  Step 1:  Email the author( slgobinath@gmail.com ) and get the Wisdom Server pack.  Step 2:  Extract the zip file and navigate into the extracted directory.  unzip product-wisdom-0.0.1.zip\ncd product-wisdom-0.0.1  Step 3:  Save the following Wisdom query into the  artifacts  directory with a name:  stock_filter.wisdomql .  @app(name='stock_filter', version='1.0.0')\n\n@source(type='http', mapping='json')\ndef stream StockStream;\n\n@sink(type='console')\ndef stream OutputStream;\n\n@query(name='FilterQuery')\nfrom StockStream\nfilter symbol == 'AMAZON'\nselect symbol, price\ninsert into OutputStream;  Step 4:  Start the Wisdom Service on port  8080  using the following command:  sh wisdom-service.sh --port 8080 artifacts/stock_filter.wisdomql  Step 5:  Using  Postman  or similar tools, send an event using HTTP POST request. For simplicity, we use  curl  to send the request.  curl -d '{\"symbol\": \"AMAZON\", \"price\": 120.0, \"volume\": 10}' -H \"Content-Type: application/json\" -X POST http://localhost:8080/WisdomApp/StockStream  After sending this request, you should see the the following output in the terminal running Wisdom service:  Event{timestamp=1524757628355, stream=OutputStream, data={symbol=AMAZON, price=120.0}, expired=false}",
            "title": "Wisdom Service"
        },
        {
            "location": "/deploy-wisdom/#wisdom-orchestra",
            "text": "Wisdom Orchestra deployment is a fancy name I use to refer managing Wisdom instances using Wisdom Manager. Wisdom Manager is a specially designed tool to deploy and manage Wisdom services. It can be used to deploy stand-alone Wisdom services or to deploy self-boosting Wisdom environment.  Wisdom Manager often requires  Apache Kafka  to coordinate and communicate with Wisdom instances. Therefore, please setup and start Apache Kakfa before running Wisdom Manager.  Step 1:  Download and extract the latest  Apache Kafka  anywhere in your system.  Step 2:  Start Apache Kafka using the following two commands from  KAFKA_HOME .  # Start Zookeeper server\nsh bin/zookeeper-server-start.sh config/zookeeper.properties\n\n# Start Kafka server\nsh bin/kafka-server-start.sh config/server.properties  Step 3:  Open another terminal in  WISDOM_HOME  and start the Wisdom Manager.  sh wisdom-manager.sh  Step 4:  Send an HTTP POST request with a Wisdom query along with a port to start that query.  curl -d \"{\\\"query\\\": \\\"@app(name='stock_filter', version='1.0.0') \\\n@source(type='http', mapping='json') \\\ndef stream StockStream; \\\n@sink(type='file.text', path='/tmp/OutputStream.txt') \\\ndef stream OutputStream; \\\n@query(name='FilterQuery') \\\nfrom StockStream \\\nfilter symbol == 'AMAZON' \\\nselect symbol, price \\\ninsert into OutputStream;\\\", \\\"port\\\": 8085}\" -H \"Content-Type: application/json\" -X POST http://localhost:8080/WisdomManager/app  Note that the OutputStream sink is a text file:  /tmp/OutputStream.txt .  Step 5:  Start  stock_filter  by sending another POST request.  curl -X POST http://localhost:8080/WisdomManager/start/stock_filter  Step 06:  Test  stock_filter  by sending a stock event.  curl -d '{\"symbol\": \"AMAZON\", \"price\": 120.0, \"volume\": 10}' -H \"Content-Type: application/json\" -X POST http://localhost:8085/WisdomApp/StockStream  After sending above event, you should have a file  /tmp/OutputStream.txt  with the following content:  Event{timestamp=1524761284277, stream=OutputStream, data={symbol=AMAZON, price=120.0}, expired=false}  Step 07:  Stop the  stock_filter  app  curl -X POST http://localhost:8080/WisdomManager/stop/stock_filter  Step 08:  Delete the  stock_filter  app  curl -X DELETE http://localhost:8080/WisdomManager/app/stock_filter  Step 09:  Stop the Wisdom Manager  curl -X POST http://localhost:8080/WisdomManager/stop",
            "title": "Wisdom Orchestra"
        },
        {
            "location": "/query-guide/",
            "text": "A Wisdom application can be created either using Java API or Wisdom Query Language. Wisdom Query Language is a SQL like query inspired by \nSiddhi Query\n. A Wisdom query should follow this template:\n\n\n<app annotation>?\n( <stream definition> | <variable definition> | ... ) + \n( <query> ) +\n;\n\n\n\n\nNOTE:\n Since I am busy with my research, I am unable to list all features implemented in Wisdom here. Once you get access to Wisdom, please check the Unit test classes to see the available features and how to use them. You can contact me at any time to clarify your issues.\n\n\nStream\n\n\nStream is the most basic component of stream processor. In Wisdom, you need to define a stream before using it. Wisdom streams are dynamically typed like Python so you cannot define attributes of a stream. At the runtime, whatever you pass will be accepted by the stream.\n\n\nJava API:\n\n\napp.defineStream(\"StockStream\");\n\n\n\n\nWisdom Query:\n\n\ndef stream StockStream;\n\n\n\n\nSelect\n\n\nSelector selects attributes and events to be inserted into the following operator. If the selector is used with attribute names, it selects the attributes from events. If a selector is used with the index of events after windows, it selects the specified events from the list of events.\n\n\nNOTE: Positive indices select events from the beginning of a list and negative indices select events from the end of a list. For example \n0\n selects the first event and \n-1\n selects the last event.\n\n\nJava API:\n\n\nSelect \nsymbol\n and \nprice\n from all events and insert them into OutputStream.\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");\n\n\n\n\nSelect last two events from window and insert them into OutputStream.\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window.lengthBatch(5)\n    .select(Index.of(-2, -1))\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nSelect \nsymbol\n and \nprice\n from all events and insert them into OutputStream.\n\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nSelect last two events from window and insert them into OutputStream.\n\n\nfrom StockStream\nselect -2, -1\ninsert into OutputStream;\n\n\n\n\nAggregate\n\n\nAggregators aggregate events and inject results into the stream. Wisdom supports the following aggregators:\n\n\n\n\nSUM\n\n\nMIN\n\n\nMAX\n\n\nAVERAGE\n\n\nCOUNT\n\n\n\n\nJava API:\n\n\nFind the total price of three stock events.\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window(Window.lengthBatch(3))\n    .aggregate(Operator.SUM(\"price\", \"total\"))\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nFind the total price of three stock events.\n\n\nfrom StockStream\nwindow.lengthBatch(3)\naggregate sum(price) as total\ninsert into OutputStream;\n\n\n\n\nFilter\n\n\nFilter is an operator to filter events coming from a stream. In Wisdom query, a \nfilter\n can be used anywhere in between \nfrom\n and \ninsert into\n statements.\n\n\nIn Java API, the \nfilter\n method accepts any \njava.util.function.Predicate<Event>\n as the argument. For user's convenient, Wisdom offers some built-in predicates:\n\n\n\n\nOperator.EQUALS\n\n\nOperator.GREATER_THAN\n\n\nOperator.GREATER_THAN_OR_EQUAL\n\n\nOperator.LESS_THAN\n\n\nOperator.LESS_THAN_OR_EQUAL\n\n\nOperator.STR_IN_ATTR and its variants\n\n\n\n\nJava API:\n\n\nFilter events having \nsymbol\n equal to \nAMAZON\n.\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(event -> \"UWO\".equals(event.get(\"symbol\")))\n    .insertInto(\"OutputStream\");\n\n\n\n\nAbove code can be written using built-in \nOperator.EQUALS\n predicate as shown below:\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(Operator.EQUALS(\"symbol\", \"AMAZON\"))\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nFilter events having \nsymbol\n equal to \nAMAZON\n.\n\n\nfrom StockStream\nfilter symbol == 'AMAZON'\ninsert into OutputStream;\n\n\n\n\nWisdom Query supports the following logical operators: \n==\n, \n>\n, \n>=\n, \n<\n, \n<=\n and \nin\n\n\nWindow\n\n\nWindows are used to batch events based on some conditions. Wisdom 0.0.1 supports the following windows:\n\n\n\n\nWindow.length\n\n\nWindow.lengthBatch\n\n\nWindow.externalTimeBatch\n\n\nUniqueWindow.lengthBatch\n\n\nUniqueWindow.externalTimeBatch\n\n\n\n\nJava API:\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window(Window.lengthBatch(3))\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nfrom StockStream\nwindow.lengthBatch(3)\ninsert into OutputStream;\n\n\n\n\nMap\n\n\nWisdom map is used to map events from one format to another format. In Java API, mapper accepts any \njava.util.function.Function<Event, Event>\n. Wisdom also provides the following built-in mappers:\n\n\n\n\nMapper.rename\n\n\nMapper.formatTime\n\n\n\n\nJava API:\n\n\nRename \nsymbol\n to \nname\n and \nprice\n to \ncost\n.\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .map(Mapper.rename(\"symbol\", \"name\"), Mapper.rename(\"price\", \"cost\"))\n    .select(\"name\", \"cost\")\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nRename \nsymbol\n to \nname\n and \nprice\n to \ncost\n.\n\n\nfrom StockStream\nmap symbol as name, price as cost\nselect name, cost\ninsert into OutputStream;\n\n\n\n\nPartition\n\n\nPartitions split streams into partitions based on given attributes to sandbox aggregations and to parallelize execution.\n\n\nJava API:\n\n\nPartition \nStockStream\n by \nsymbol\n\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .partitionBy(\"symbol\")\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");\n\n\n\n\nWisdom Query:\n\n\nRename \nsymbol\n to \nname\n and \nprice\n to \ncost\n.\n\n\nfrom StockStream\npartition by symbol\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nPattern\n\n\nPatterns are another important aspect of stream processing. Wisdom supports regular patterns, count patterns and logical patterns.\n\n\nJava API:\n\n\nWisdom pattern to detect \nIBM\n or \nWSO2\n followed by \nORACLE\n.\n\n\napp.defineStream(\"StockStream\");\napp.defineStream(\"OutputStream\");\n\n// e1 or e2 -> e3\nPattern e1 = Pattern.pattern(\"Pattern1\", \"e1\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"IBM\"));\nPattern e2 = Pattern.pattern(\"Pattern2\", \"e2\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"WSO2\"));\nPattern e3 = Pattern.pattern(\"Pattern3\", \"e3\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"ORACLE\"));\n\nPattern finalPattern = Pattern.followedBy(Pattern.or(e1, e2), e3);\n\napp.defineQuery(\"query1\")\n    .from(finalPattern)\n    .select(\"e1.symbol\", \"e2.symbol\", \"e3.symbol\")\n    .insertInto(\"OutputStream\");\n\n\n\n\nStill I have not implemented Wisdom Query for pattern. Therefore, patterns can be used only in Java.\n\n\nSource\n\n\nSource is an event source for a Wisdom stream. Currently Wisdom provides the following sources:\n\n\n\n\nHTTP\n\n\nKafka\n\n\nCSV\n\n\nPcap\n\n\n\n\nJava API:\n\n\nDefine Kafka source in Java.\n\n\nwisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\n\nwisdomApp.addSource(\"StockStream\", new KafkaSource(\"localhost:9092\"));\n\n\n\n\nWisdom Query:\n\n\nDefine Kafka source in Wisdom Query.\n\n\n@source(type='kafka', bootstrap='localhost:9092')\ndef stream StockStream;\n\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nSink\n\n\nSink receives events from a stream and send them to the relative receiver. Currently Wisdom supports the following sinks:\n\n\n\n\nHTTP\n\n\nKafka\n\n\nCSV\n\n\nText File\n\n\nConsole\n\n\n\n\nJava API:\n\n\nDefine HTTP sink in Java.\n\n\nwisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\n\nwisdomApp.addSink(\"OutputStream\", new HTTPSink(\"http://localhost:9999/streamReceiver\"));\n\n\n\n\nWisdom Query:\n\n\nDefine HTTP sink in Wisdom Query.\n\n\ndef stream StockStream;\n\n@sink(type='http', mapping='json', endpoint='http://localhost:9999/streamReceiver')\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;\n\n\n\n\nVariable\n\n\nWisdom variables are used to store a value in memory. A Wisdom query can be defined using predefined variables.\n\n\nJava API:\n\n\nA dynamic size length window defined using a variable.\n\n\napp.defineStream(\"StockStream\");\napp.defineStream(\"OutputStream\");\napp.defineStream(\"VariableStream\");\nVariable<Integer> variable = app.defineVariable(\"window_length\", 3);\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(Operator.GREATER_THAN(\"price\", 55.0))\n    .window(Window.lengthBatch(variable))\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");\n\napp.defineQuery(\"query2\")\n    .from(\"VariableStream\")\n    .filter(Operator.GREATER_THAN(\"value\", 0))\n    .map(Mapper.rename(\"value\", \"window_length\"))\n    .update(\"window_length\");\n\n\n\n\nWisdom Query:\n\n\nA dynamic size lengthBatch window defined using a variable.\n\n\ndef stream StockStream;\ndef stream OutputStream;\ndef stream VariableStream;\ndef variable window_length = 3;\n\nfrom StockStream\nfilter price > 55.0\nwindow.lengthBatch($window_length)\nselect symbol, price\ninsert into OutputStream;\n\nfrom VariableStream\nfilter value > 0\nmap value as window_length\nupdate window_length;",
            "title": "Wisdom Query Guide"
        },
        {
            "location": "/query-guide/#stream",
            "text": "Stream is the most basic component of stream processor. In Wisdom, you need to define a stream before using it. Wisdom streams are dynamically typed like Python so you cannot define attributes of a stream. At the runtime, whatever you pass will be accepted by the stream.  Java API:  app.defineStream(\"StockStream\");  Wisdom Query:  def stream StockStream;",
            "title": "Stream"
        },
        {
            "location": "/query-guide/#select",
            "text": "Selector selects attributes and events to be inserted into the following operator. If the selector is used with attribute names, it selects the attributes from events. If a selector is used with the index of events after windows, it selects the specified events from the list of events.  NOTE: Positive indices select events from the beginning of a list and negative indices select events from the end of a list. For example  0  selects the first event and  -1  selects the last event.  Java API:  Select  symbol  and  price  from all events and insert them into OutputStream.  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");  Select last two events from window and insert them into OutputStream.  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window.lengthBatch(5)\n    .select(Index.of(-2, -1))\n    .insertInto(\"OutputStream\");  Wisdom Query:  Select  symbol  and  price  from all events and insert them into OutputStream.  from StockStream\nselect symbol, price\ninsert into OutputStream;  Select last two events from window and insert them into OutputStream.  from StockStream\nselect -2, -1\ninsert into OutputStream;",
            "title": "Select"
        },
        {
            "location": "/query-guide/#aggregate",
            "text": "Aggregators aggregate events and inject results into the stream. Wisdom supports the following aggregators:   SUM  MIN  MAX  AVERAGE  COUNT   Java API:  Find the total price of three stock events.  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window(Window.lengthBatch(3))\n    .aggregate(Operator.SUM(\"price\", \"total\"))\n    .insertInto(\"OutputStream\");  Wisdom Query:  Find the total price of three stock events.  from StockStream\nwindow.lengthBatch(3)\naggregate sum(price) as total\ninsert into OutputStream;",
            "title": "Aggregate"
        },
        {
            "location": "/query-guide/#filter",
            "text": "Filter is an operator to filter events coming from a stream. In Wisdom query, a  filter  can be used anywhere in between  from  and  insert into  statements.  In Java API, the  filter  method accepts any  java.util.function.Predicate<Event>  as the argument. For user's convenient, Wisdom offers some built-in predicates:   Operator.EQUALS  Operator.GREATER_THAN  Operator.GREATER_THAN_OR_EQUAL  Operator.LESS_THAN  Operator.LESS_THAN_OR_EQUAL  Operator.STR_IN_ATTR and its variants   Java API:  Filter events having  symbol  equal to  AMAZON .  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(event -> \"UWO\".equals(event.get(\"symbol\")))\n    .insertInto(\"OutputStream\");  Above code can be written using built-in  Operator.EQUALS  predicate as shown below:  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(Operator.EQUALS(\"symbol\", \"AMAZON\"))\n    .insertInto(\"OutputStream\");  Wisdom Query:  Filter events having  symbol  equal to  AMAZON .  from StockStream\nfilter symbol == 'AMAZON'\ninsert into OutputStream;  Wisdom Query supports the following logical operators:  == ,  > ,  >= ,  < ,  <=  and  in",
            "title": "Filter"
        },
        {
            "location": "/query-guide/#window",
            "text": "Windows are used to batch events based on some conditions. Wisdom 0.0.1 supports the following windows:   Window.length  Window.lengthBatch  Window.externalTimeBatch  UniqueWindow.lengthBatch  UniqueWindow.externalTimeBatch   Java API:  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .window(Window.lengthBatch(3))\n    .insertInto(\"OutputStream\");  Wisdom Query:  from StockStream\nwindow.lengthBatch(3)\ninsert into OutputStream;",
            "title": "Window"
        },
        {
            "location": "/query-guide/#map",
            "text": "Wisdom map is used to map events from one format to another format. In Java API, mapper accepts any  java.util.function.Function<Event, Event> . Wisdom also provides the following built-in mappers:   Mapper.rename  Mapper.formatTime   Java API:  Rename  symbol  to  name  and  price  to  cost .  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .map(Mapper.rename(\"symbol\", \"name\"), Mapper.rename(\"price\", \"cost\"))\n    .select(\"name\", \"cost\")\n    .insertInto(\"OutputStream\");  Wisdom Query:  Rename  symbol  to  name  and  price  to  cost .  from StockStream\nmap symbol as name, price as cost\nselect name, cost\ninsert into OutputStream;",
            "title": "Map"
        },
        {
            "location": "/query-guide/#partition",
            "text": "Partitions split streams into partitions based on given attributes to sandbox aggregations and to parallelize execution.  Java API:  Partition  StockStream  by  symbol  app.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .partitionBy(\"symbol\")\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");  Wisdom Query:  Rename  symbol  to  name  and  price  to  cost .  from StockStream\npartition by symbol\nselect symbol, price\ninsert into OutputStream;",
            "title": "Partition"
        },
        {
            "location": "/query-guide/#pattern",
            "text": "Patterns are another important aspect of stream processing. Wisdom supports regular patterns, count patterns and logical patterns.  Java API:  Wisdom pattern to detect  IBM  or  WSO2  followed by  ORACLE .  app.defineStream(\"StockStream\");\napp.defineStream(\"OutputStream\");\n\n// e1 or e2 -> e3\nPattern e1 = Pattern.pattern(\"Pattern1\", \"e1\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"IBM\"));\nPattern e2 = Pattern.pattern(\"Pattern2\", \"e2\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"WSO2\"));\nPattern e3 = Pattern.pattern(\"Pattern3\", \"e3\", \"StockStream\")\n        .filter(event -> event.get(\"symbol\").equals(\"ORACLE\"));\n\nPattern finalPattern = Pattern.followedBy(Pattern.or(e1, e2), e3);\n\napp.defineQuery(\"query1\")\n    .from(finalPattern)\n    .select(\"e1.symbol\", \"e2.symbol\", \"e3.symbol\")\n    .insertInto(\"OutputStream\");  Still I have not implemented Wisdom Query for pattern. Therefore, patterns can be used only in Java.",
            "title": "Pattern"
        },
        {
            "location": "/query-guide/#source",
            "text": "Source is an event source for a Wisdom stream. Currently Wisdom provides the following sources:   HTTP  Kafka  CSV  Pcap   Java API:  Define Kafka source in Java.  wisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\n\nwisdomApp.addSource(\"StockStream\", new KafkaSource(\"localhost:9092\"));  Wisdom Query:  Define Kafka source in Wisdom Query.  @source(type='kafka', bootstrap='localhost:9092')\ndef stream StockStream;\n\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;",
            "title": "Source"
        },
        {
            "location": "/query-guide/#sink",
            "text": "Sink receives events from a stream and send them to the relative receiver. Currently Wisdom supports the following sinks:   HTTP  Kafka  CSV  Text File  Console   Java API:  Define HTTP sink in Java.  wisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\n\nwisdomApp.addSink(\"OutputStream\", new HTTPSink(\"http://localhost:9999/streamReceiver\"));  Wisdom Query:  Define HTTP sink in Wisdom Query.  def stream StockStream;\n\n@sink(type='http', mapping='json', endpoint='http://localhost:9999/streamReceiver')\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;",
            "title": "Sink"
        },
        {
            "location": "/query-guide/#variable",
            "text": "Wisdom variables are used to store a value in memory. A Wisdom query can be defined using predefined variables.  Java API:  A dynamic size length window defined using a variable.  app.defineStream(\"StockStream\");\napp.defineStream(\"OutputStream\");\napp.defineStream(\"VariableStream\");\nVariable<Integer> variable = app.defineVariable(\"window_length\", 3);\n\napp.defineQuery(\"query1\")\n    .from(\"StockStream\")\n    .filter(Operator.GREATER_THAN(\"price\", 55.0))\n    .window(Window.lengthBatch(variable))\n    .select(\"symbol\", \"price\")\n    .insertInto(\"OutputStream\");\n\napp.defineQuery(\"query2\")\n    .from(\"VariableStream\")\n    .filter(Operator.GREATER_THAN(\"value\", 0))\n    .map(Mapper.rename(\"value\", \"window_length\"))\n    .update(\"window_length\");  Wisdom Query:  A dynamic size lengthBatch window defined using a variable.  def stream StockStream;\ndef stream OutputStream;\ndef stream VariableStream;\ndef variable window_length = 3;\n\nfrom StockStream\nfilter price > 55.0\nwindow.lengthBatch($window_length)\nselect symbol, price\ninsert into OutputStream;\n\nfrom VariableStream\nfilter value > 0\nmap value as window_length\nupdate window_length;",
            "title": "Variable"
        },
        {
            "location": "/wisdom-extensions/",
            "text": "Writing extensions for Wisdom is super easy if you know Java. An extension can be a \nWindow\n, \nSource\n, \nSink\n, or \nMapper\n. In this section, I explain how to create a new sink to write events to a text file. All existing windows, sources, sinks, and mappers are written as extensions following the same technique.\n\n\nCreate New Sink Extension\n\n\nStep 1:\n Create a new Maven project in your favorite IDE.\n\n\nStep 2:\n Open \npom.xml\n file and add \nwisdom-core\n dependency as show below:\n\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>\n\n\n\n\nStep 3:\n Create a new class \ncom.javahelps.wisdom.extensions.file.sink.TextFileSink\n and extend \ncom.javahelps.wisdom.core.stream.output.Sink\n. Depending on your extension type, you may need to override different classes:\n\n\n\n\nWindow - \ncom.javahelps.wisdom.core.window.Window\n\n\nSource - \ncom.javahelps.wisdom.core.stream.input.Source\n\n\nSink - \ncom.javahelps.wisdom.core.stream.output.Sink\n\n\nMapper - \ncom.javahelps.wisdom.core.map.Mapper\n\n\n\n\npackage com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\npublic class TextFileSink extends Sink {\n\n}\n\n\n\n\nStep 4:\n Annotate the class using \nWisdomExtension\n annotation and define namespace as \nfile.text\n which will be used to identify this sink later in Wisdom query. This step is common for all Wisdom extensions.\n\n\npackage com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.extension.WisdomExtension;\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\n@WisdomExtension(\"file.text\")\npublic class TextFileSink extends Sink {\n\n}\n\n\n\n\nStep 5:\n Override all required methods. For text file sink, overriding \npublish\n method is enough. You may need \nstart\n, \ninit\n and \nstop\n if your sink is complex as Kafka sink.\n\n\npackage com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.event.Event;\nimport com.javahelps.wisdom.core.exception.WisdomAppValidationException;\nimport com.javahelps.wisdom.core.extension.WisdomExtension;\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.List;\nimport java.util.Map;\n\n@WisdomExtension(\"file.text\")\npublic class TextFileSink extends Sink {\n\n    private final String path;\n\n    public TextFileSink(Map<String, ?> properties) {\n        super(properties);\n        this.path = (String) properties.get(\"path\");\n        if (this.path == null) {\n            throw new WisdomAppValidationException(\"Required property 'path' for TextFile sink not found\");\n        }\n    }\n\n    @Override\n    public void start() {\n        // Do nothing\n    }\n\n    @Override\n    public void init(WisdomApp wisdomApp, String streamId) {\n\n    }\n\n    @Override\n    public void publish(List<Event> events) throws IOException {\n        try (PrintWriter writer = new PrintWriter(new FileWriter(this.path, true))) {\n            for (Event event : events) {\n                writer.println(event);\n            }\n        }\n    }\n\n    @Override\n    public void stop() {\n        // Do nothing\n    }\n}\n\n\n\n\nNow you are ready to use this sink in your Wisdom app.\n\n\nUse Extension in Java API\n\n\nStep 1:\n Create a new test class in the same project \ncom.javahelps.wisdom.extensions.file.sink.TestTextFileSink\n.\n\n\nStep 2:\n Create a static initialization block and import the custom extension.\n\n\npackage com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.extension.ImportsManager;\n\npublic class TestTextFileSink {\n\n    static {\n        ImportsManager.INSTANCE.use(TextFileSink.class);\n    }\n}\n\n\n\n\nWe use \nImportsManager\n to import selected extension, instead of searching the complete classpath to avoid unnecessary delays. It also reduces unnecessary complexities in Android applications.\n\n\nStep 3:\n Create a new Wisdom app using the \nfile.text\n sink. Note that we are using the namespace \nfile.text\n to create this sink.\n\n\nWisdomApp wisdomApp = new WisdomApp();\nwisdomApp.defineStream(\"StockStream\");\nwisdomApp.defineStream(\"OutputStream\");\n\nwisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\nwisdomApp.addSink(\"OutputStream\", Sink.create(\"file.text\", Map.of(\"path\", \"output.log\")));\n\n\nwisdomApp.start();\n\nInputHandler stockStreamInputHandler = wisdomApp.getInputHandler(\"StockStream\");\nstockStreamInputHandler.send(EventGenerator.generate(\"symbol\", \"IBM\", \"price\", 50.0, \"volume\", 10));\nstockStreamInputHandler.send(EventGenerator.generate(\"symbol\", \"WSO2\", \"price\", 60.0, \"volume\", 15));\n\n\n\n\nUse Extension in Wisdom Query\n\n\nAbove sink can be used in a Wisdom query as given below:\n\n\ndef stream StockStream;\n@sink(type='file.text', path='output.log')\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;JAR\n\n\n\n\nDeploy in Wisdom Server\n\n\nStep 1:\n Build the jar file containing \ncom.javahelps.wisdom.extensions.file.sink.TextFileSink\n.\n\n\nmvn clean package\n\n\n\n\nStep 2:\n Copy and paste the \ntarget/xxx.jar\n file into \nWISDOM_HOME/lib\n directory.\n\n\nStep 3:\n Restart running Wisdom services.",
            "title": "Writing Extensions"
        },
        {
            "location": "/wisdom-extensions/#create-new-sink-extension",
            "text": "Step 1:  Create a new Maven project in your favorite IDE.  Step 2:  Open  pom.xml  file and add  wisdom-core  dependency as show below:  <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <modelVersion>4.0.0</modelVersion>\n\n    <groupId>com.javahelps</groupId>\n    <artifactId>wisdom-java-api</artifactId>\n    <version>1.0-SNAPSHOT</version>\n    <build>\n        <plugins>\n            <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-compiler-plugin</artifactId>\n                <configuration>\n                    <source>1.9</source>\n                    <target>1.9</target>\n                </configuration>\n            </plugin>\n        </plugins>\n    </build>\n\n    <properties>\n        <wisdom.version>0.0.1</wisdom.version>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>com.javahelps.wisdom</groupId>\n            <artifactId>wisdom-core</artifactId>\n            <version>${wisdom.version}</version>\n        </dependency>\n    </dependencies>\n\n</project>  Step 3:  Create a new class  com.javahelps.wisdom.extensions.file.sink.TextFileSink  and extend  com.javahelps.wisdom.core.stream.output.Sink . Depending on your extension type, you may need to override different classes:   Window -  com.javahelps.wisdom.core.window.Window  Source -  com.javahelps.wisdom.core.stream.input.Source  Sink -  com.javahelps.wisdom.core.stream.output.Sink  Mapper -  com.javahelps.wisdom.core.map.Mapper   package com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\npublic class TextFileSink extends Sink {\n\n}  Step 4:  Annotate the class using  WisdomExtension  annotation and define namespace as  file.text  which will be used to identify this sink later in Wisdom query. This step is common for all Wisdom extensions.  package com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.extension.WisdomExtension;\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\n@WisdomExtension(\"file.text\")\npublic class TextFileSink extends Sink {\n\n}  Step 5:  Override all required methods. For text file sink, overriding  publish  method is enough. You may need  start ,  init  and  stop  if your sink is complex as Kafka sink.  package com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.WisdomApp;\nimport com.javahelps.wisdom.core.event.Event;\nimport com.javahelps.wisdom.core.exception.WisdomAppValidationException;\nimport com.javahelps.wisdom.core.extension.WisdomExtension;\nimport com.javahelps.wisdom.core.stream.output.Sink;\n\nimport java.io.FileWriter;\nimport java.io.IOException;\nimport java.io.PrintWriter;\nimport java.util.List;\nimport java.util.Map;\n\n@WisdomExtension(\"file.text\")\npublic class TextFileSink extends Sink {\n\n    private final String path;\n\n    public TextFileSink(Map<String, ?> properties) {\n        super(properties);\n        this.path = (String) properties.get(\"path\");\n        if (this.path == null) {\n            throw new WisdomAppValidationException(\"Required property 'path' for TextFile sink not found\");\n        }\n    }\n\n    @Override\n    public void start() {\n        // Do nothing\n    }\n\n    @Override\n    public void init(WisdomApp wisdomApp, String streamId) {\n\n    }\n\n    @Override\n    public void publish(List<Event> events) throws IOException {\n        try (PrintWriter writer = new PrintWriter(new FileWriter(this.path, true))) {\n            for (Event event : events) {\n                writer.println(event);\n            }\n        }\n    }\n\n    @Override\n    public void stop() {\n        // Do nothing\n    }\n}  Now you are ready to use this sink in your Wisdom app.",
            "title": "Create New Sink Extension"
        },
        {
            "location": "/wisdom-extensions/#use-extension-in-java-api",
            "text": "Step 1:  Create a new test class in the same project  com.javahelps.wisdom.extensions.file.sink.TestTextFileSink .  Step 2:  Create a static initialization block and import the custom extension.  package com.javahelps.wisdom.extensions.file.sink;\n\nimport com.javahelps.wisdom.core.extension.ImportsManager;\n\npublic class TestTextFileSink {\n\n    static {\n        ImportsManager.INSTANCE.use(TextFileSink.class);\n    }\n}  We use  ImportsManager  to import selected extension, instead of searching the complete classpath to avoid unnecessary delays. It also reduces unnecessary complexities in Android applications.  Step 3:  Create a new Wisdom app using the  file.text  sink. Note that we are using the namespace  file.text  to create this sink.  WisdomApp wisdomApp = new WisdomApp();\nwisdomApp.defineStream(\"StockStream\");\nwisdomApp.defineStream(\"OutputStream\");\n\nwisdomApp.defineQuery(\"query1\")\n        .from(\"StockStream\")\n        .select(\"symbol\", \"price\")\n        .insertInto(\"OutputStream\");\nwisdomApp.addSink(\"OutputStream\", Sink.create(\"file.text\", Map.of(\"path\", \"output.log\")));\n\n\nwisdomApp.start();\n\nInputHandler stockStreamInputHandler = wisdomApp.getInputHandler(\"StockStream\");\nstockStreamInputHandler.send(EventGenerator.generate(\"symbol\", \"IBM\", \"price\", 50.0, \"volume\", 10));\nstockStreamInputHandler.send(EventGenerator.generate(\"symbol\", \"WSO2\", \"price\", 60.0, \"volume\", 15));",
            "title": "Use Extension in Java API"
        },
        {
            "location": "/wisdom-extensions/#use-extension-in-wisdom-query",
            "text": "Above sink can be used in a Wisdom query as given below:  def stream StockStream;\n@sink(type='file.text', path='output.log')\ndef stream OutputStream;\n\nfrom StockStream\nselect symbol, price\ninsert into OutputStream;JAR",
            "title": "Use Extension in Wisdom Query"
        },
        {
            "location": "/wisdom-extensions/#deploy-in-wisdom-server",
            "text": "Step 1:  Build the jar file containing  com.javahelps.wisdom.extensions.file.sink.TextFileSink .  mvn clean package  Step 2:  Copy and paste the  target/xxx.jar  file into  WISDOM_HOME/lib  directory.  Step 3:  Restart running Wisdom services.",
            "title": "Deploy in Wisdom Server"
        },
        {
            "location": "/intrusion-detection/",
            "text": "Intrusion Detection\n\n\nFollowing queries were developed to detect network attacks in \nCICIDS 2017\n dataset. We developed the following rules based on facts behind each attacks. Even though we obtained an average precision of 99.98%, we are not responsible for failure of detecting real time attacks.\n\n\nFTP Brute Force Attack\n\n\nIn FTP Brute Force attack, an attacker tries different combinations of username and password to login to the FTP server. Therefore, there should be significantly large amount of failed attempts within a short period of time.\n\n\n@app(name='FTPBruteForceDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\ndef variable time_threshold = time.sec(1);\ndef variable count_threshold = 7;\n\nfrom PacketStream\n    filter 'FTP' == app_protocol and '530 Login incorrect' in data\n    partition by destIp\n    window.externalTimeBatch('timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;\n\n\n\n\nHTTP Slow Header Attack\n\n\nHTTP Slow Header attack is a Denial of Service(DOS) attack in which a victim server is compromized by sending too many HTTP incomplete requests with random \nKeep-Alive\n time. For more details, read: \nHow Secure are Web Servers? An Empirical Study of Slow HTTP DoS Attacks and Detection\n.\n\n\n@app(name='SlowHeaderDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\ndef variable time_threshold = time.sec(1);\ndef variable count_threshold = 998;\n\nfrom PacketStream\n    filter 'http' == app_protocol and destPort == 80 and '\\r\\n\\r\\n' in data and 'Keep-Alive: \\\\d+' in data\n    partition by destIp\n    window.externalTimeBatch('timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;\n\n\n\n\nPort Scanning\n\n\nEven though Port Scanning is a common technique used by attackers, it is hard to fit all types of port scans into a single CEP rule. The following rule is developed to detect \nnmap -sS\n port scan. For more details, please visit \nPort Scanning Techniques\n.\n\n\n\n@app(name='PortScanDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\n@config(trainable=true, minimum=100, maximum=60000, step=-1)\ndef variable time_threshold = 761;\n\n@config(trainable=true, minimum=3, maximum=1000, step=1)\ndef variable count_threshold = 3;\n\nfrom PacketStream\n    filter syn == true and ack == false\n    partition by srcIp, destIp\n    window.unique:externalTimeBatch('destPort', 'timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;",
            "title": "Intrusion Detection"
        },
        {
            "location": "/intrusion-detection/#intrusion-detection",
            "text": "Following queries were developed to detect network attacks in  CICIDS 2017  dataset. We developed the following rules based on facts behind each attacks. Even though we obtained an average precision of 99.98%, we are not responsible for failure of detecting real time attacks.",
            "title": "Intrusion Detection"
        },
        {
            "location": "/intrusion-detection/#ftp-brute-force-attack",
            "text": "In FTP Brute Force attack, an attacker tries different combinations of username and password to login to the FTP server. Therefore, there should be significantly large amount of failed attempts within a short period of time.  @app(name='FTPBruteForceDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\ndef variable time_threshold = time.sec(1);\ndef variable count_threshold = 7;\n\nfrom PacketStream\n    filter 'FTP' == app_protocol and '530 Login incorrect' in data\n    partition by destIp\n    window.externalTimeBatch('timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;",
            "title": "FTP Brute Force Attack"
        },
        {
            "location": "/intrusion-detection/#http-slow-header-attack",
            "text": "HTTP Slow Header attack is a Denial of Service(DOS) attack in which a victim server is compromized by sending too many HTTP incomplete requests with random  Keep-Alive  time. For more details, read:  How Secure are Web Servers? An Empirical Study of Slow HTTP DoS Attacks and Detection .  @app(name='SlowHeaderDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\ndef variable time_threshold = time.sec(1);\ndef variable count_threshold = 998;\n\nfrom PacketStream\n    filter 'http' == app_protocol and destPort == 80 and '\\r\\n\\r\\n' in data and 'Keep-Alive: \\\\d+' in data\n    partition by destIp\n    window.externalTimeBatch('timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;",
            "title": "HTTP Slow Header Attack"
        },
        {
            "location": "/intrusion-detection/#port-scanning",
            "text": "Even though Port Scanning is a common technique used by attackers, it is hard to fit all types of port scans into a single CEP rule. The following rule is developed to detect  nmap -sS  port scan. For more details, please visit  Port Scanning Techniques .  \n@app(name='PortScanDetector', version='1.0.0')\ndef stream PacketStream;\ndef stream AttackStream;\n\n@config(trainable=true, minimum=100, maximum=60000, step=-1)\ndef variable time_threshold = 761;\n\n@config(trainable=true, minimum=3, maximum=1000, step=1)\ndef variable count_threshold = 3;\n\nfrom PacketStream\n    filter syn == true and ack == false\n    partition by srcIp, destIp\n    window.unique:externalTimeBatch('destPort', 'timestamp', $time_threshold)\n    aggregate count() as no_of_packets\n    filter no_of_packets >= $count_threshold\n    select srcIp, destIp, no_of_packets, timestamp\ninsert into AttackStream;",
            "title": "Port Scanning"
        }
    ]
}